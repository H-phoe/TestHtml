<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Input Volume</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            margin: 0;
        }
        #volume-meter {
            width: 100%;
            height: 30px;
            background-color: lightgray;
            margin: 20px 0;
            position: relative;
        }
        #volume-level {
            height: 100%;
            background-color: green;
            width: 0;
        }
        #volume-value {
            font-size: 1.5em;
        }
    </style>
</head>
<body>
    <h1>Audio Input Volume</h1>
    <div id="volume-meter">
        <div id="volume-level"></div>
    </div>
    <div id="volume-value">0</div>
    <button id="start-button">Start</button>
    <button id="stop-button" disabled>Stop</button>
    <script>
        let audioContext;
        let analyser;
        let microphone;
        let javascriptNode;
        let isRunning = false;

        document.getElementById('start-button').addEventListener('click', startMonitoring);
        document.getElementById('stop-button').addEventListener('click', stopMonitoring);

        function startMonitoring() {
            if (isRunning) return;

            isRunning = true;
            document.getElementById('start-button').disabled = true;
            document.getElementById('stop-button').disabled = false;

            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            analyser.smoothingTimeConstant = 0.3;

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    microphone = audioContext.createMediaStreamSource(stream);
                    microphone.connect(analyser);

                    javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);
                    javascriptNode.onaudioprocess = () => {
                        const array = new Uint8Array(analyser.frequencyBinCount);
                        analyser.getByteFrequencyData(array);

                        let values = 0;
                        for (let i = 0; i < array.length; i++) {
                            values += array[i];
                        }
                        const average = values / array.length;

                        const volumeLevel = document.getElementById('volume-level');
                        const volumeValue = document.getElementById('volume-value');

                        volumeLevel.style.width = `${average}%`;
                        volumeValue.textContent = Math.round(average);
                    };

                    microphone.connect(javascriptNode);
                    javascriptNode.connect(audioContext.destination);
                })
                .catch(err => {
                    console.error('Error accessing microphone:', err);
                    isRunning = false;
                    document.getElementById('start-button').disabled = false;
                    document.getElementById('stop-button').disabled = true;
                });
        }

        function stopMonitoring() {
            if (!isRunning) return;

            isRunning = false;
            document.getElementById('start-button').disabled = false;
            document.getElementById('stop-button').disabled = true;

            if (microphone) {
                microphone.disconnect();
            }
            if (javascriptNode) {
                javascriptNode.disconnect();
            }
            if (audioContext) {
                audioContext.close();
            }
        }
    </script>
</body>
</html>